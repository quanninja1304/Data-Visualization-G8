{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c852fe11",
      "metadata": {
        "id": "c852fe11"
      },
      "source": [
        "# **A0. Project Kick-off: Dataset Overview and Analytical Framing**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60bbc552",
      "metadata": {
        "id": "60bbc552"
      },
      "source": [
        "## **A0.1. Introduction to the Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7697a3b4",
      "metadata": {
        "id": "7697a3b4"
      },
      "source": [
        "Our project will analyze the *\"News Popularity in Multiple Social Media Platforms\"* dataset. This dataset is uniquely suited for our objective — demonstrating the power of data preparation, because its raw form presents significant, realistic barriers to analysis.\n",
        "\n",
        "The data is provided in **13 separate files**, which can be categorized into two distinct types:\n",
        "\n",
        "*   **Metadata File (`News_Final.csv`):** This is the central anchor of our dataset. It contains descriptive information for each of the ~93,000 news articles, including:\n",
        "    *   `IDLink`: A unique identifier for each article.\n",
        "    *   `PublishDate`: The timestamp of publication, crucial for any time-based analysis.\n",
        "    *   `Topic`: The article's category (e.g., `economy`, `microsoft`).\n",
        "    *   `Facebook`, `GooglePlus`, `LinkedIn`: The final popularity scores after a 48-hour period.\n",
        "\n",
        "*   **Social Feedback Files (12 CSVs):** These files contain the granular, time-series popularity data.\n",
        "    *   Their structure (`Platform_Topic.csv`) separates data by both social media platform and news topic.\n",
        "    *   Their most defining characteristic is their **\"wide\" data format**, where columns `TS1` through `TS144` represent the popularity score at sequential 20-minute intervals."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cab07c9",
      "metadata": {
        "id": "1cab07c9"
      },
      "source": [
        "## **A0.2. The Core Challenge: Data in an Unusable State**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5be915df",
      "metadata": {
        "id": "5be915df"
      },
      "source": [
        "In its raw state, this dataset is **analytically hostile**. It is impossible to draw meaningful, multi-dimensional conclusions without a *significant and deliberate preparation* phase. Our project will be the story of overcoming **three fundamental challenges**:\n",
        "\n",
        "*   **Challenge 1: Data Fragmentation.** The insights are scattered across 13 separate files. It's impossible to compare platform performance or topic trends without first integrating this data into a single, unified structure.\n",
        "\n",
        "*   **Challenge 2: Structural Unsuitability.** The \"wide\" format of the feedback files, with 144 columns for time, is optimized for storage, not analysis. We cannot plot a trend over time or compare engagement lifecycles with this structure.\n",
        "\n",
        "*   **Challenge 3: Data Integrity Issues.** Several critical features are in an unusable format. The `PublishDate` is stored as text, making temporal analysis impossible. Furthermore, popularity scores use `-1` as a placeholder for missing data, which would severely distort any statistical calculation (e.g., the average).\n",
        "\n",
        "⇒ The central premise of our project is that this raw data, while rich in potential, **actively prevents insight**. Our data preparation work is the key that will unlock this potential."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a81be03",
      "metadata": {
        "id": "5a81be03"
      },
      "source": [
        "## **A0.3. Guiding Analytical Questions**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ddc7fd0",
      "metadata": {
        "id": "2ddc7fd0"
      },
      "source": [
        "To guide our exploration and structure our data story, we will focus on answering a set of high-level strategic questions. These questions have been specifically chosen because they are **impossible to answer with the raw data** and can only be addressed after a comprehensive preparation pipeline.\n",
        "\n",
        "1.  **The Temporal Question:** How does the **time of day** and **day of the week** an article is published influence its **engagement trajectory** on different social media platforms?\n",
        "\n",
        "2.  **The Platform Personality Question:** Do different social media platforms exhibit **unique engagement \"personalities\"**? For instance, does LinkedIn engagement peak during business hours while Facebook's peaks during evenings and weekends?\n",
        "\n",
        "3.  **The Content Lifecycle Question:** Is there a discernible difference in the popularity lifecycle between **\"hard news\"** topics (e.g., `Economy`, `Palestine`) and **\"corporate/political\"** topics (e.g., `Microsoft`, `Obama`)? Do some topics burn brightly but fade quickly, while others have a longer \"tail\" of engagement?\n",
        "\n",
        "4.  **The Engagement Velocity Question:** Which platform provides the fastest initial **\"lift\"** or engagement velocity within the first few hours of an article's publication?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23a087ce",
      "metadata": {
        "id": "23a087ce"
      },
      "source": [
        "## **A0.4. Why These Questions? The Link to Data Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb5d2cc9",
      "metadata": {
        "id": "bb5d2cc9"
      },
      "source": [
        "These questions are not arbitrary; they directly map to the **specific technical challenges** we must overcome. Each preparation task is a necessary step that **enables a specific type of analysis**, making our guiding questions answerable.\n",
        "\n",
        "*   **To investigate the impact of time (Question 1):**\n",
        "    *   **We must** convert the `PublishDate` column from a text `object` into a machine-readable **`datetime` format**.\n",
        "    *   **We must** then **engineer new features** from this `datetime` object, such as `hour_of_day` and `day_of_week`.\n",
        "    *   ⇒ **This enables** us to group and aggregate our data by time intervals—a capability that is completely absent in the raw data.\n",
        "\n",
        "*   **To compare platform performance (Question 2):**\n",
        "    *   **We must** **integrate the 13 fragmented files** into a single, cohesive master dataset.\n",
        "    *   During this process, we will create a new `Platform` column to label the source of each popularity record.\n",
        "    *   ⇒ **This enables** direct, side-by-side analysis of platform behavior, which is impossible when the data is siloed.\n",
        "\n",
        "*   **To analyze engagement lifecycles and velocity (Questions 3 & 4):**\n",
        "    *   **We must** perform a **structural wide-to-long transformation** on the time-series data (using `pd.melt`).\n",
        "    *   This reshapes the 144 `TS` columns into a single, usable `TimeSlice` variable.\n",
        "    *   ⇒ **This enables** us to plot popularity as a function of time, allowing us to visualize and measure the \"lifecycle\" and \"velocity\" of engagement. This is the most critical transformation in our project.\n",
        "\n",
        "⇒ Our data preparation is therefore a **targeted strategy**. The quality of our final story is directly dependent on how well we execute these transformations to make answering our guiding questions **possible**."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
